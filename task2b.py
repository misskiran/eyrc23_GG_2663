# -*- coding: utf-8 -*-
"""task2b.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1AX30-4j5j4xh61V3DEJ4DHL5KO0zLQtB

# New Section
"""

from google.colab import drive
drive.mount('/my_drive')

pip install scikit-learn



import tensorflow as tf
import numpy as np
import pandas as pd
import os
from sklearn.model_selection import train_test_split



import tensorflow as tf
from tensorflow.keras.applications import MobileNetV2
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, BatchNormalization, Dropout
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.callbacks import LearningRateScheduler

# Define the number of classes
num_classes = 5

# Define the image size
image_size = (224, 224)

# Create a base model with pre-trained weights (MobileNetV2 in this case)
base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(image_size[0], image_size[1], 3))

# Freeze the base model layers
for layer in base_model.layers:
    layer.trainable = False

# Create a new model on top of the base model
model = Sequential([
    base_model,
    GlobalAveragePooling2D(),
    Dense(1024, activation='relu'),
    BatchNormalization(),
    Dropout(0.5),
    Dense(num_classes, activation='softmax')
])

# Define a learning rate schedule
def learning_rate_schedule(epoch, lr):
    if epoch < 5:
        return lr
    else:
        return lr * tf.math.exp(-0.1)

# Compile the model
model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])

# Define data augmentation
datagen = ImageDataGenerator(
    rescale=1.0 / 255.0,
    rotation_range=30,
    width_shift_range=0.3,
    height_shift_range=0.3,
    shear_range=0.3,
    zoom_range=0.3,
    horizontal_flip=True,
    fill_mode='nearest'
)

# Load and prepare your training data
train_data = datagen.flow_from_directory(
    '/content/drive/MyDrive/Colab Notebooks/training',
    target_size=image_size,
    batch_size=32,
    class_mode='categorical'
)

# Set up the learning rate schedule callback
lr_schedule = LearningRateScheduler(learning_rate_schedule)

# Train the model with the learning rate schedule
history = model.fit(train_data, epochs=15, callbacks=[lr_schedule])

# Save the trained model
model.save('trained_model.h5')

import tensorflow as tf
from tensorflow.keras.applications import MobileNetV2
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, BatchNormalization, Dropout
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.callbacks import LearningRateScheduler

# Define the number of classes
num_classes = 5

# Define the image size
image_size = (224, 224)

# Create a base model with pre-trained weights (MobileNetV2 in this case)
base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(image_size[0], image_size[1], 3))

# Freeze the base model layers
for layer in base_model.layers:
    layer.trainable = False

# Create a new model on top of the base model
model = Sequential([
    base_model,
    GlobalAveragePooling2D(),
    Dense(1024, activation='relu'),
    BatchNormalization(),
    Dropout(0.5),
    Dense(num_classes, activation='softmax')
])

# Define a learning rate schedule
def learning_rate_schedule(epoch, lr):
    if epoch < 5:
        return lr
    else:
        return lr * tf.math.exp(-0.1)

# Compile the model
model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])

# Define data augmentation
datagen = ImageDataGenerator(
    rescale=1.0 / 255.0,
    rotation_range=30,
    width_shift_range=0.3,
    height_shift_range=0.3,
    shear_range=0.3,
    zoom_range=0.3,
    horizontal_flip=True,
    fill_mode='nearest'
)

# Load and prepare your training data with custom class labels
train_data = datagen.flow_from_directory(
    '/content/drive/MyDrive/Colab Notebooks/training',
    target_size=image_size,
    batch_size=32,
    class_mode='categorical',
    classes=['Combat', 'DestroyedBuildings', 'Fire', 'Humanitarian Aid and rehabilitation', 'Military vehicles and weapons']
)

# Set up the learning rate schedule callback
lr_schedule = LearningRateScheduler(learning_rate_schedule)

# Train the model with the learning rate schedule
history = model.fit(train_data, epochs=15, callbacks=[lr_schedule])

# Save the trained model
model.save('trained_model3.h5')

import tensorflow as tf
import numpy as np

# Load the trained model
model = tf.keras.models.load_model('trained_model1.h5')

# Define the class labels
class_labels = {
    0: "combat",
    1: "destroyedbuilding",
    2: "fire",
    3: "humanitarianaid",
    4: "militaryvehicles"
}

# Define the path to your test image
test_image_path = '/content/drive/MyDrive/Colab Notebooks/testing/testing/rehab2.jpeg'

# Load and preprocess the test image
test_image = tf.keras.preprocessing.image.load_img(test_image_path, target_size=(224, 224))
test_image = tf.keras.preprocessing.image.img_to_array(test_image)
test_image = test_image / 255.0  # Normalize the pixel values to [0, 1]
test_image = np.expand_dims(test_image, axis=0)  # Add a batch dimension

# Make predictions using the model
predictions = model.predict(test_image)
predicted_class = np.argmax(predictions[0])
predicted_event = class_labels[predicted_class]

# Print the predicted event
print("Predicted event:", predicted_event)

model.save('/content/drive/MyDrive/Colab Notebooks/trained_model3.h5')



model.save('/content/drive/MyDrive/Colab Notebooks/trained_model_updated.h5')

import tensorflow as tf
import numpy as np

# Load the trained model
model = tf.keras.models.load_model('trained_model3.h5')

# Define the class labels
class_labels = {
    0: "combat",
    1: "destroyedbuilding",
    2: "fire",
    3: "humanitarianaid",
    4: "militaryvehicles"
}

# Define the path to your test image
test_image_path = '/content/drive/MyDrive/Colab Notebooks/testing/testing/building2.jpeg'

# Load and preprocess the test image
test_image = tf.keras.preprocessing.image.load_img(test_image_path, target_size=(224, 224))
test_image = tf.keras.preprocessing.image.img_to_array(test_image)
test_image = test_image / 255.0  # Normalize the pixel values to [0, 1]
test_image = np.expand_dims(test_image, axis=0)  # Add a batch dimension

# Make predictions using the model
predictions = model.predict(test_image)
predicted_class = np.argmax(predictions[0])
predicted_event = class_labels[predicted_class]

# Print the predicted event
print("Predicted event:", predicted_event)

import tensorflow as tf
from tensorflow.keras.applications import ResNet50
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, BatchNormalization, Dropout
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.callbacks import LearningRateScheduler

# Define the number of classes
num_classes = 5

# Define the image size
image_size = (224, 224)

# Create a base model with pre-trained weights (ResNet50 in this case)
base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(image_size[0], image_size[1], 3))

# Freeze the base model layers
for layer in base_model.layers:
    layer.trainable = False

# Create a new model on top of the base model
model = Sequential([
    base_model,
    GlobalAveragePooling2D(),
    Dense(1024, activation='relu'),
    BatchNormalization(),
    Dropout(0.5),
    Dense(512, activation='relu'),
    BatchNormalization(),
    Dropout(0.5),
    Dense(num_classes, activation='softmax')
])

# Define a learning rate schedule
def learning_rate_schedule(epoch, lr):
    if epoch < 5:
        return lr
    else:
        return lr * tf.math.exp(-0.1)

# Compile the model
model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])

# Define data augmentation
datagen = ImageDataGenerator(
    rescale=1.0 / 255.0,
    rotation_range=30,
    width_shift_range=0.3,
    height_shift_range=0.3,
    shear_range=0.3,
    zoom_range=0.3,
    horizontal_flip=True,
    fill_mode='nearest'
)

# Load and prepare your training data with custom class labels
train_data = datagen.flow_from_directory(
    '/content/drive/MyDrive/Colab Notebooks/training',
    target_size=image_size,
    batch_size=32,
    class_mode='categorical',
    classes=['Combat', 'DestroyedBuildings', 'Fire', 'Humanitarian Aid and rehabilitation', 'Military vehicles and weapons']
)

# Set up the learning rate schedule callback
lr_schedule = LearningRateScheduler(learning_rate_schedule)

# Train the model with the learning rate schedule
history = model.fit(train_data, epochs=20, callbacks=[lr_schedule])

# Save the trained model
model.save('trained_model4.h5')

model.save('/content/drive/MyDrive/Colab Notebooks/trained_model7.h5')

import tensorflow as tf
import numpy as np

# Load the trained model
model = tf.keras.models.load_model('trained_model6.h5')

# Define the class labels
class_labels = {
    0: "combat",
    1: "destroyedbuilding",
    2: "fire",
    3: "humanitarianaid",
    4: "militaryvehicles"
}

# Define a list of test image paths
test_image_paths = [
    '/content/drive/MyDrive/Colab Notebooks/testing/testing/building1.jpeg',
    '/content/drive/MyDrive/Colab Notebooks/testing/testing/building2.jpeg',
    '/content/drive/MyDrive/Colab Notebooks/testing/testing/combat2.jpeg',
    '/content/drive/MyDrive/Colab Notebooks/testing/testing/combat1.jpeg',
    '/content/drive/MyDrive/Colab Notebooks/testing/testing/fire1.jpeg',
    '/content/drive/MyDrive/Colab Notebooks/testing/testing/fire2.jpeg',
    '/content/drive/MyDrive/Colab Notebooks/testing/testing/rehab2.jpeg',
    '/content/drive/MyDrive/Colab Notebooks/testing/testing/rehab1.jpeg',
    '/content/drive/MyDrive/Colab Notebooks/testing/testing/military2.jpeg',
    '/content/drive/MyDrive/Colab Notebooks/testing/testing/military1.jpeg'

    # Add more test image paths here
]

# Loop through the test images and make predictions
for test_image_path in test_image_paths:
    # Load and preprocess the test image
    test_image = tf.keras.preprocessing.image.load_img(test_image_path, target_size=(224, 224))
    test_image = tf.keras.preprocessing.image.img_to_array(test_image)
    test_image = test_image / 255.0  # Normalize the pixel values to [0, 1]
    test_image = np.expand_dims(test_image, axis=0)  # Add a batch dimension

    # Make predictions using the model
    predictions = model.predict(test_image)
    predicted_class = np.argmax(predictions[0])
    predicted_event = class_labels[predicted_class]

    # Print the predicted event
    print("Predicted event for", test_image_path, ":", predicted_event)

import tensorflow as tf
import numpy as np

# Load the trained model
model = tf.keras.models.load_model('trained_model1.h5')

# Define the class labels
class_labels = {
    0: "combat",
    1: "destroyedbuilding",
    2: "fire",
    3: "humanitarianaid",
    4: "militaryvehicles"
}

# Define a list of test image paths
test_image_paths = [
    '/content/drive/MyDrive/Colab Notebooks/testing/testing/building1.jpeg',
    '/content/drive/MyDrive/Colab Notebooks/testing/testing/building2.jpeg',
    '/content/drive/MyDrive/Colab Notebooks/testing/testing/combat2.jpeg',
    '/content/drive/MyDrive/Colab Notebooks/testing/testing/combat1.jpeg',
    '/content/drive/MyDrive/Colab Notebooks/testing/testing/fire1.jpeg',
    '/content/drive/MyDrive/Colab Notebooks/testing/testing/fire2.jpeg',
    '/content/drive/MyDrive/Colab Notebooks/testing/testing/rehab2.jpeg',
    '/content/drive/MyDrive/Colab Notebooks/testing/testing/rehab1.jpeg',
    '/content/drive/MyDrive/Colab Notebooks/testing/testing/military2.jpeg',
    '/content/drive/MyDrive/Colab Notebooks/testing/testing/military1.jpeg'

    # Add more test image paths here
]

# Loop through the test images and make predictions
for test_image_path in test_image_paths:
    # Load and preprocess the test image
    test_image = tf.keras.preprocessing.image.load_img(test_image_path, target_size=(224, 224))
    test_image = tf.keras.preprocessing.image.img_to_array(test_image)
    test_image = test_image / 255.0  # Normalize the pixel values to [0, 1]
    test_image = np.expand_dims(test_image, axis=0)  # Add a batch dimension

    # Make predictions using the model
    predictions = model.predict(test_image)
    predicted_class = np.argmax(predictions[0])
    predicted_event = class_labels[predicted_class]

    # Print the predicted event
    print("Predicted event for", test_image_path, ":", predicted_event)

import tensorflow as tf
import numpy as np

# Load the trained model
model = tf.keras.models.load_model('trained_model3.h5')

# Define the class labels
class_labels = {
    0: "combat",
    1: "destroyedbuilding",
    2: "fire",
    3: "humanitarianaid",
    4: "militaryvehicles"
}

# Define a list of test image paths
test_image_paths = [
    '/content/drive/MyDrive/Colab Notebooks/testing/testing/building1.jpeg',
    '/content/drive/MyDrive/Colab Notebooks/testing/testing/building2.jpeg',
    '/content/drive/MyDrive/Colab Notebooks/testing/testing/combat2.jpeg',
    '/content/drive/MyDrive/Colab Notebooks/testing/testing/combat1.jpeg',
    '/content/drive/MyDrive/Colab Notebooks/testing/testing/fire1.jpeg',
    '/content/drive/MyDrive/Colab Notebooks/testing/testing/fire2.jpeg',
    '/content/drive/MyDrive/Colab Notebooks/testing/testing/rehab2.jpeg',
    '/content/drive/MyDrive/Colab Notebooks/testing/testing/rehab1.jpeg',
    '/content/drive/MyDrive/Colab Notebooks/testing/testing/military2.jpeg',
    '/content/drive/MyDrive/Colab Notebooks/testing/testing/military1.jpeg'

    # Add more test image paths here
]

# Loop through the test images and make predictions
for test_image_path in test_image_paths:
    # Load and preprocess the test image
    test_image = tf.keras.preprocessing.image.load_img(test_image_path, target_size=(224, 224))
    test_image = tf.keras.preprocessing.image.img_to_array(test_image)
    test_image = test_image / 255.0  # Normalize the pixel values to [0, 1]
    test_image = np.expand_dims(test_image, axis=0)  # Add a batch dimension

    # Make predictions using the model
    predictions = model.predict(test_image)
    predicted_class = np.argmax(predictions[0])
    predicted_event = class_labels[predicted_class]

    # Print the predicted event
    print("Predicted event for", test_image_path, ":", predicted_event)
